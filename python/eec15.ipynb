{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EnquÃªte emploi en continu 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experimental Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os              # General OS commands\n",
    "import numpy as np     # NumPy\n",
    "import pandas as pd    # Python Data Analysis Library\n",
    "import zipfile         # Compress/decompress ZIP files\n",
    "import sqlite3         # SQLite3 Database Driver\n",
    "import re              # Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model, metrics\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Never truncate columns, display all the data\n",
    "from IPython.display import display, HTML\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "# Display floating-point numbers with 4 decimals in `pandas.DataFrame`\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "\n",
    "# Ordered dictionaries remember the order that items were inserted\n",
    "from collections import OrderedDict\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Display MatPlotLib stuff inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zip_filename = \"../data/ee-insee-2015_custom-sqlite.zip\"\n",
    "eedb = zip_filename.replace(\"-sqlite.zip\", \".sqlite\")\n",
    "\n",
    "if not os.path.exists(eedb):\n",
    "    with zipfile.ZipFile(zip_filename) as zip_file:\n",
    "        zip_file.extractall(\"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with sqlite3.connect(eedb) as con:\n",
    "    query = \"SELECT * FROM eec15_custom\"\n",
    "    eec15 = pd.read_sql_query(query, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a (\"female\" x \"enfant\") interaction variable\n",
    "bool_ = eec15[[\"enfants_\", \"female_\"]].astype(bool)\n",
    "eec15[\"female_enfants_\"] = (bool_.enfants_ & bool_.female_).astype(int)\n",
    "\n",
    "# Drop data we don't need\n",
    "eec15 = eec15[eec15.age60_ == 0]\n",
    "eec15 = eec15.drop(\"age60_\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build a list of parameters to include in the model, using regex\n",
    "# https://www.datarobot.com/blog/multiple-regression-using-statsmodels/\n",
    "filters = {\n",
    "    \"age\": \"^age[0-9]{2}_$\",\n",
    "    \"diploma\": \"^dip[0-9]{2}_$\",\n",
    "    \"etranger\": \"^etranger_$\",\n",
    "    \"domtom\": \"^domtom_$\",\n",
    "#     \"trim\": \"^trim$\",\n",
    "    \"female\": \"^female_$\",\n",
    "    \"enfants\": \"^enfants_$\",\n",
    "#     \"female_enfants\": \"^female_enfants_$\",\n",
    "    \"region\": \"^region[1-2]_$\"\n",
    "}\n",
    "params = {k: sorted([x for x in eec15.columns if re.match(r, x)]) for (k, r) in filters.items()}\n",
    "\n",
    "# Avoid the dummy variable trap\n",
    "params = {k: (v if len(v) == 1 else v[:-1]) for (k, v) in params.items()}\n",
    "params[\"region\"] += [\"region2_\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trims = [\"t{}\".format(x) for x in sorted(eec15[\"trim\"].unique())]\n",
    "eec15_ = {t: eec15[eec15.trim == int(t[1])] for t in trims}\n",
    "X = {t: eec15_[t][sum(params.values(), [])] for t in eec15_}\n",
    "y = {t: eec15_[t][\"actop_\"] for t in eec15_}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fee7afdb3d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAF0CAYAAACDhlvVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fee85a9e1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.crosstab(eec15.actop_, eec15.female_).plot(kind='bar', stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of employment: 0.347426515966\n"
     ]
    }
   ],
   "source": [
    "print \"Probability of employment:\", eec15[\"actop_\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Fitting the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model using `trim=1` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = OrderedDict({\n",
    "    \"linear_sk\": linear_model.LinearRegression(fit_intercept=True).fit(X[\"t1\"], y[\"t1\"]),\n",
    "    \"linear_sm\": sm.OLS(y[\"t1\"], sm.add_constant(X[\"t1\"])).fit(disp=False),\n",
    "    \n",
    "    \"logit_sk\": linear_model.LogisticRegression(solver=\"sag\").fit(X[\"t1\"], y[\"t1\"]),\n",
    "    \"logit_sm\": sm.Logit(y[\"t1\"], sm.add_constant(X[\"t1\"])).fit(disp=False),\n",
    "\n",
    "#     \"probit_sk\": no `probit` in sci-kit learn\n",
    "    \"probit_sm\": sm.Probit(y[\"t1\"], sm.add_constant(X[\"t1\"])).fit(disp=False),  \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# These functions allow us to enable/disable models throughout the notebook\n",
    "# by simply commenting them out in the dictionary above\n",
    "def enabled(models_list):\n",
    "    if not isinstance(models_list, list):\n",
    "        raise Exception(\"Argument to 'enabled()' should be a list.\")\n",
    "    return all([m in models for m in models_list])\n",
    "\n",
    "def enabled_models(models_list):\n",
    "    return [x for x in models_list if x in models]\n",
    "\n",
    "def model_type(model):\n",
    "    return model[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 actop_   R-squared:                       0.268\n",
      "Model:                            OLS   Adj. R-squared:                  0.267\n",
      "Method:                 Least Squares   F-statistic:                     1400.\n",
      "Date:                Tue, 28 Feb 2017   Prob (F-statistic):               0.00\n",
      "Time:                        23:13:50   Log-Likelihood:                -38183.\n",
      "No. Observations:               72838   AIC:                         7.641e+04\n",
      "Df Residuals:                   72818   BIC:                         7.659e+04\n",
      "Df Model:                          19                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.3677      0.007     52.357      0.000         0.354     0.381\n",
      "etranger_      0.1289      0.006     20.711      0.000         0.117     0.141\n",
      "age15_         0.3206      0.004     72.382      0.000         0.312     0.329\n",
      "age30_         0.0495      0.005     10.438      0.000         0.040     0.059\n",
      "age40_        -0.0073      0.004     -1.634      0.102        -0.016     0.001\n",
      "dip10_        -0.3453      0.006    -58.146      0.000        -0.357    -0.334\n",
      "dip11_        -0.3799      0.009    -41.620      0.000        -0.398    -0.362\n",
      "dip30_        -0.2223      0.016    -13.832      0.000        -0.254    -0.191\n",
      "dip31_        -0.3302      0.007    -50.711      0.000        -0.343    -0.317\n",
      "dip33_        -0.3673      0.011    -34.146      0.000        -0.388    -0.346\n",
      "dip41_        -0.0953      0.007    -13.720      0.000        -0.109    -0.082\n",
      "dip42_        -0.2746      0.006    -46.937      0.000        -0.286    -0.263\n",
      "dip50_        -0.2058      0.005    -40.387      0.000        -0.216    -0.196\n",
      "dip60_         0.0370      0.006      5.957      0.000         0.025     0.049\n",
      "dip70_        -0.0465      0.013     -3.512      0.000        -0.072    -0.021\n",
      "female_        0.0841      0.003     27.211      0.000         0.078     0.090\n",
      "enfants_      -0.0717      0.004    -20.034      0.000        -0.079    -0.065\n",
      "region1_       0.0348      0.005      6.500      0.000         0.024     0.045\n",
      "region2_       0.0448      0.008      5.956      0.000         0.030     0.060\n",
      "domtom_        0.1124      0.005     23.147      0.000         0.103     0.122\n",
      "==============================================================================\n",
      "Omnibus:                     4664.504   Durbin-Watson:                   1.880\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4251.511\n",
      "Skew:                           0.529   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.468   Cond. No.                         18.3\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 actop_   No. Observations:                72838\n",
      "Model:                          Logit   Df Residuals:                    72818\n",
      "Method:                           MLE   Df Model:                           19\n",
      "Date:                Tue, 28 Feb 2017   Pseudo R-squ.:                  0.2220\n",
      "Time:                        23:13:50   Log-Likelihood:                -36757.\n",
      "converged:                       True   LL-Null:                       -47245.\n",
      "                                        LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.6978      0.041    -17.122      0.000        -0.778    -0.618\n",
      "etranger_      0.6915      0.035     19.827      0.000         0.623     0.760\n",
      "age15_         1.5972      0.026     62.597      0.000         1.547     1.647\n",
      "age30_         0.3117      0.029     10.661      0.000         0.254     0.369\n",
      "age40_        -0.0758      0.028     -2.714      0.007        -0.131    -0.021\n",
      "dip10_        -1.9053      0.037    -50.911      0.000        -1.979    -1.832\n",
      "dip11_        -2.3686      0.072    -32.829      0.000        -2.510    -2.227\n",
      "dip30_        -1.0517      0.095    -11.076      0.000        -1.238    -0.866\n",
      "dip31_        -1.8161      0.042    -43.478      0.000        -1.898    -1.734\n",
      "dip33_        -2.1377      0.082    -26.053      0.000        -2.299    -1.977\n",
      "dip41_        -0.5214      0.038    -13.835      0.000        -0.595    -0.448\n",
      "dip42_        -1.3976      0.034    -41.453      0.000        -1.464    -1.332\n",
      "dip50_        -0.9673      0.028    -34.429      0.000        -1.022    -0.912\n",
      "dip60_         0.1498      0.035      4.321      0.000         0.082     0.218\n",
      "dip70_        -0.1829      0.069     -2.665      0.008        -0.317    -0.048\n",
      "female_        0.5176      0.019     27.660      0.000         0.481     0.554\n",
      "enfants_      -0.4556      0.022    -21.183      0.000        -0.498    -0.413\n",
      "region1_       0.2039      0.033      6.257      0.000         0.140     0.268\n",
      "region2_       0.2614      0.045      5.838      0.000         0.174     0.349\n",
      "domtom_        0.6042      0.027     21.995      0.000         0.550     0.658\n",
      "==============================================================================\n",
      "\n",
      "                          Probit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 actop_   No. Observations:                72838\n",
      "Model:                         Probit   Df Residuals:                    72818\n",
      "Method:                           MLE   Df Model:                           19\n",
      "Date:                Tue, 28 Feb 2017   Pseudo R-squ.:                  0.2213\n",
      "Time:                        23:13:50   Log-Likelihood:                -36790.\n",
      "converged:                       True   LL-Null:                       -47245.\n",
      "                                        LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.4084      0.024    -17.055      0.000        -0.455    -0.361\n",
      "etranger_      0.4105      0.020     20.054      0.000         0.370     0.451\n",
      "age15_         0.9455      0.015     63.398      0.000         0.916     0.975\n",
      "age30_         0.1671      0.017      9.953      0.000         0.134     0.200\n",
      "age40_        -0.0488      0.016     -3.057      0.002        -0.080    -0.018\n",
      "dip10_        -1.1090      0.021    -52.166      0.000        -1.151    -1.067\n",
      "dip11_        -1.3303      0.038    -35.100      0.000        -1.405    -1.256\n",
      "dip30_        -0.6348      0.055    -11.518      0.000        -0.743    -0.527\n",
      "dip31_        -1.0496      0.023    -44.685      0.000        -1.096    -1.004\n",
      "dip33_        -1.2131      0.043    -28.299      0.000        -1.297    -1.129\n",
      "dip41_        -0.3054      0.023    -13.380      0.000        -0.350    -0.261\n",
      "dip42_        -0.8262      0.020    -41.726      0.000        -0.865    -0.787\n",
      "dip50_        -0.5785      0.017    -34.620      0.000        -0.611    -0.546\n",
      "dip60_         0.1148      0.021      5.483      0.000         0.074     0.156\n",
      "dip70_        -0.1178      0.042     -2.811      0.005        -0.200    -0.036\n",
      "female_        0.3049      0.011     27.981      0.000         0.284     0.326\n",
      "enfants_      -0.2666      0.012    -21.358      0.000        -0.291    -0.242\n",
      "region1_       0.1179      0.019      6.225      0.000         0.081     0.155\n",
      "region2_       0.1536      0.026      5.871      0.000         0.102     0.205\n",
      "domtom_        0.3553      0.016     21.723      0.000         0.323     0.387\n",
      "==============================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display summary for models that have one\n",
    "for m in enabled_models([\"linear_sm\", \"logit_sm\", \"probit_sm\"]):\n",
    "    # display(models[m].summary)        # HTML\n",
    "    print models[m].summary(); print    # raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logit\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age15_</th>\n",
       "      <th>age30_</th>\n",
       "      <th>age40_</th>\n",
       "      <th>const</th>\n",
       "      <th>dip10_</th>\n",
       "      <th>dip11_</th>\n",
       "      <th>dip30_</th>\n",
       "      <th>dip31_</th>\n",
       "      <th>dip33_</th>\n",
       "      <th>dip41_</th>\n",
       "      <th>dip42_</th>\n",
       "      <th>dip50_</th>\n",
       "      <th>dip60_</th>\n",
       "      <th>dip70_</th>\n",
       "      <th>domtom_</th>\n",
       "      <th>enfants_</th>\n",
       "      <th>etranger_</th>\n",
       "      <th>female_</th>\n",
       "      <th>region1_</th>\n",
       "      <th>region2_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sm</th>\n",
       "      <td>1.5972</td>\n",
       "      <td>0.3117</td>\n",
       "      <td>-0.0758</td>\n",
       "      <td>-0.6978</td>\n",
       "      <td>-1.9053</td>\n",
       "      <td>-2.3686</td>\n",
       "      <td>-1.0517</td>\n",
       "      <td>-1.8161</td>\n",
       "      <td>-2.1377</td>\n",
       "      <td>-0.5214</td>\n",
       "      <td>-1.3976</td>\n",
       "      <td>-0.9673</td>\n",
       "      <td>0.1498</td>\n",
       "      <td>-0.1829</td>\n",
       "      <td>0.6042</td>\n",
       "      <td>-0.4556</td>\n",
       "      <td>0.6915</td>\n",
       "      <td>0.5176</td>\n",
       "      <td>0.2039</td>\n",
       "      <td>0.2614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sk</th>\n",
       "      <td>1.5949</td>\n",
       "      <td>0.3096</td>\n",
       "      <td>-0.0766</td>\n",
       "      <td>-0.7008</td>\n",
       "      <td>-1.8975</td>\n",
       "      <td>-2.3516</td>\n",
       "      <td>-1.0374</td>\n",
       "      <td>-1.8079</td>\n",
       "      <td>-2.1187</td>\n",
       "      <td>-0.5149</td>\n",
       "      <td>-1.3906</td>\n",
       "      <td>-0.9618</td>\n",
       "      <td>0.1555</td>\n",
       "      <td>-0.1775</td>\n",
       "      <td>0.6052</td>\n",
       "      <td>-0.4552</td>\n",
       "      <td>0.6925</td>\n",
       "      <td>0.5166</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.2608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff</th>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>-0.0078</td>\n",
       "      <td>-0.0171</td>\n",
       "      <td>-0.0143</td>\n",
       "      <td>-0.0082</td>\n",
       "      <td>-0.0190</td>\n",
       "      <td>-0.0065</td>\n",
       "      <td>-0.0070</td>\n",
       "      <td>-0.0055</td>\n",
       "      <td>-0.0057</td>\n",
       "      <td>-0.0054</td>\n",
       "      <td>-0.0010</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>-0.0010</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age15_  age30_  age40_   const  dip10_  dip11_  dip30_  dip31_  dip33_  \\\n",
       "sm   1.5972  0.3117  -0.0758 -0.6978 -1.9053 -2.3686 -1.0517 -1.8161 -2.1377   \n",
       "sk   1.5949  0.3096  -0.0766 -0.7008 -1.8975 -2.3516 -1.0374 -1.8079 -2.1187   \n",
       "diff 0.0023  0.0022  0.0008  0.0031  -0.0078 -0.0171 -0.0143 -0.0082 -0.0190   \n",
       "\n",
       "      dip41_  dip42_  dip50_  dip60_  dip70_  domtom_  enfants_  etranger_  \\\n",
       "sm   -0.5214 -1.3976 -0.9673 0.1498  -0.1829 0.6042   -0.4556   0.6915       \n",
       "sk   -0.5149 -1.3906 -0.9618 0.1555  -0.1775 0.6052   -0.4552   0.6925       \n",
       "diff -0.0065 -0.0070 -0.0055 -0.0057 -0.0054 -0.0010  -0.0003   -0.0010      \n",
       "\n",
       "      female_  region1_  region2_  \n",
       "sm   0.5176   0.2039    0.2614     \n",
       "sk   0.5166   0.2030    0.2608     \n",
       "diff 0.0009   0.0009    0.0006     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age15_</th>\n",
       "      <th>age30_</th>\n",
       "      <th>age40_</th>\n",
       "      <th>const</th>\n",
       "      <th>dip10_</th>\n",
       "      <th>dip11_</th>\n",
       "      <th>dip30_</th>\n",
       "      <th>dip31_</th>\n",
       "      <th>dip33_</th>\n",
       "      <th>dip41_</th>\n",
       "      <th>dip42_</th>\n",
       "      <th>dip50_</th>\n",
       "      <th>dip60_</th>\n",
       "      <th>dip70_</th>\n",
       "      <th>domtom_</th>\n",
       "      <th>enfants_</th>\n",
       "      <th>etranger_</th>\n",
       "      <th>female_</th>\n",
       "      <th>region1_</th>\n",
       "      <th>region2_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sm</th>\n",
       "      <td>0.3206</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>-0.0073</td>\n",
       "      <td>0.3677</td>\n",
       "      <td>-0.3453</td>\n",
       "      <td>-0.3799</td>\n",
       "      <td>-0.2223</td>\n",
       "      <td>-0.3302</td>\n",
       "      <td>-0.3673</td>\n",
       "      <td>-0.0953</td>\n",
       "      <td>-0.2746</td>\n",
       "      <td>-0.2058</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>-0.0465</td>\n",
       "      <td>0.1124</td>\n",
       "      <td>-0.0717</td>\n",
       "      <td>0.1289</td>\n",
       "      <td>0.0841</td>\n",
       "      <td>0.0348</td>\n",
       "      <td>0.0448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sk</th>\n",
       "      <td>0.3206</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>-0.0073</td>\n",
       "      <td>0.3677</td>\n",
       "      <td>-0.3453</td>\n",
       "      <td>-0.3799</td>\n",
       "      <td>-0.2223</td>\n",
       "      <td>-0.3302</td>\n",
       "      <td>-0.3673</td>\n",
       "      <td>-0.0953</td>\n",
       "      <td>-0.2746</td>\n",
       "      <td>-0.2058</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>-0.0465</td>\n",
       "      <td>0.1124</td>\n",
       "      <td>-0.0717</td>\n",
       "      <td>0.1289</td>\n",
       "      <td>0.0841</td>\n",
       "      <td>0.0348</td>\n",
       "      <td>0.0448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff</th>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age15_  age30_  age40_  const  dip10_  dip11_  dip30_  dip31_  dip33_  \\\n",
       "sm   0.3206  0.0495  -0.0073 0.3677 -0.3453 -0.3799 -0.2223 -0.3302 -0.3673   \n",
       "sk   0.3206  0.0495  -0.0073 0.3677 -0.3453 -0.3799 -0.2223 -0.3302 -0.3673   \n",
       "diff -0.0000 -0.0000 0.0000  0.0000 -0.0000 0.0000  0.0000  -0.0000 0.0000    \n",
       "\n",
       "      dip41_  dip42_  dip50_  dip60_  dip70_  domtom_  enfants_  etranger_  \\\n",
       "sm   -0.0953 -0.2746 -0.2058 0.0370  -0.0465 0.1124   -0.0717   0.1289       \n",
       "sk   -0.0953 -0.2746 -0.2058 0.0370  -0.0465 0.1124   -0.0717   0.1289       \n",
       "diff 0.0000  0.0000  0.0000  -0.0000 -0.0000 -0.0000  0.0000    -0.0000      \n",
       "\n",
       "      female_  region1_  region2_  \n",
       "sm   0.0841   0.0348    0.0448     \n",
       "sk   0.0841   0.0348    0.0448     \n",
       "diff -0.0000  -0.0000   -0.0000    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare the coefficients from both fits (they should be the same)\n",
    "regressors = list(X[\"t1\"].columns) + [\"const\"]\n",
    "coeffs = {}\n",
    "\n",
    "if enabled([\"linear_sm\", \"linear_sk\"]):\n",
    "    coeffs[\"linear\"] = pd.DataFrame(index=regressors)\n",
    "    coeffs[\"linear\"][\"sm\"] = models[\"linear_sm\"].params\n",
    "    coeffs[\"linear\"][\"sk\"] = pd.Series(np.append(models[\"linear_sk\"].coef_, models[\"linear_sk\"].intercept_), index=regressors)\n",
    "    coeffs[\"linear\"][\"diff\"] = coeffs[\"linear\"][\"sm\"] - coeffs[\"linear\"][\"sk\"]\n",
    "    \n",
    "if enabled([\"logit_sm\", \"logit_sk\"]):\n",
    "    coeffs[\"logit\"] = pd.DataFrame(index=regressors)\n",
    "    coeffs[\"logit\"][\"sm\"] = models[\"logit_sm\"].params\n",
    "    coeffs[\"logit\"][\"sk\"] = pd.Series(np.append(models[\"logit_sk\"].coef_, models[\"logit_sk\"].intercept_), index=regressors)\n",
    "    coeffs[\"logit\"][\"diff\"] = coeffs[\"logit\"][\"sm\"] - coeffs[\"logit\"][\"sk\"]\n",
    "    \n",
    "for mtype in coeffs:\n",
    "    print mtype\n",
    "    display(coeffs[mtype].sort_index().transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the model to test data (`trim=2/3/4`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_sk</th>\n",
       "      <th>logit_sm</th>\n",
       "      <th>probit_sm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t1</th>\n",
       "      <td>0.7626</td>\n",
       "      <td>0.7624</td>\n",
       "      <td>0.7617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t2</th>\n",
       "      <td>0.7681</td>\n",
       "      <td>0.7675</td>\n",
       "      <td>0.7668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3</th>\n",
       "      <td>0.7606</td>\n",
       "      <td>0.7600</td>\n",
       "      <td>0.7594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t4</th>\n",
       "      <td>0.7636</td>\n",
       "      <td>0.7635</td>\n",
       "      <td>0.7629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    linear_sk  logit_sm  probit_sm\n",
       "t1 0.7626     0.7624    0.7617    \n",
       "t2 0.7681     0.7675    0.7668    \n",
       "t3 0.7606     0.7600    0.7594    \n",
       "t4 0.7636     0.7635    0.7629    "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the accuracy of the model on the training & test sets\n",
    "accuracy = pd.DataFrame(index=trims)\n",
    "\n",
    "# To avoid the pitfall from the above calculation, we need to map [0, 1] -> {0, 1}\n",
    "# We define a threshold probability above which we consider an individual to be employed\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "if enabled([\"linear_sk\"]):\n",
    "    accuracy[\"linear_sk\"] = pd.Series()\n",
    "    for t in trims:\n",
    "        predicted = models[\"linear_sk\"].predict(X[t])\n",
    "        predicted = np.where(predicted < THRESHOLD, 0, 1)\n",
    "        accuracy[\"linear_sk\"][t] = metrics.accuracy_score(y[t], predicted)\n",
    "\n",
    "for m in enabled_models([\"logit_sm\", \"probit_sm\"]):\n",
    "    accuracy[m] = pd.Series()\n",
    "    for t in trims:\n",
    "        # Note: the three methods for computing `predicted` are equivalent\n",
    "        # predicted = np.where(models[m].predict_proba(X[t]).T[1] < THRESHOLD, 0, 1)\n",
    "        # predicted = models[m].predict(X[t])    # THRESHOLD = 0.5 is implied\n",
    "        predicted = np.where(models[m].predict(sm.add_constant(X[t])) < THRESHOLD, 0, 1)\n",
    "        accuracy[m][t] = metrics.accuracy_score(y[t], predicted)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Marginal Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "marginal_effects = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytically (using the derivative formula)\n",
    "#### Logit\n",
    "Recall that:\n",
    "$$EM(x_1) = \\frac{\\partial{\\mathbb{E}[y|x]}}{\\partial{x_1}} = \\beta_1 \\Lambda'(\\beta_0 + \\beta_1 x_1 + ... )$$\n",
    "where\n",
    "$$\\Lambda(x^T\\beta) = \\frac{e^{x^T\\beta}}{1+e^{x^T\\beta}} = P(y=1|x) = \\mathbb{E}[y|x]$$\n",
    "and\n",
    "$$\\Lambda'(x) = \\frac{e^x}{(1+e^x)^2} = \\Lambda(x)\\Lambda(1-x) = \\Lambda(x)\\Lambda(-x)$$\n",
    "\n",
    "#### Probit\n",
    "Recall that:\n",
    "$$EM(x_1) = \\frac{\\partial{\\mathbb{E}[y|x]}}{\\partial{x_1}} = \\beta_1 \\Phi'(\\beta_0 + \\beta_1 x_1 + ... ) = \\beta_1 \\phi(\\beta_0 + \\beta_1 x_1 + ... )$$\n",
    "where\n",
    "$$\\Phi(x^T\\beta) = P(y=1|x) = \\mathbb{E}[y|x]$$\n",
    "is the *cumulative distribution function* and\n",
    "$$\\Phi'(x) = \\phi(x) = \\frac{1}{\\sqrt{2\\pi}}\\, e^{-\\frac{x^2}{2}}$$\n",
    "the *probability density function* of a **standard** normal distribution ($\\mu = 0, \\sigma = 1$)\n",
    "\n",
    "**Note**: for each parameter, we calculate the *mean* marginal effect over the entire training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if enabled([\"logit_sm\"]) or enabled([\"logit_sk\"]):\n",
    "    def link(x):\n",
    "        return math.exp(x)/(1+math.exp(x))\n",
    "\n",
    "    def dlink(x):\n",
    "        return link(x)*link(-x)\n",
    "    \n",
    "    y_fitted = X[\"t1\"].dot(coeffs[\"logit\"][\"sm\"][:-1])\n",
    "    y_fitted += coeffs[\"logit\"][\"sm\"][\"const\"]\n",
    "    dlambda_y = y_fitted.map(dlambda)\n",
    "    \n",
    "    marginal_effects[\"analytical\"] = coeffs[\"logit\"][\"sm\"]*dlambda_y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By \"rule-of-thumb\"\n",
    "Note (from above) that:\n",
    "$$EM(x_1) = \\beta_1 \\Lambda'(\\beta_0 + \\beta_1 x_1 + ... )$$\n",
    "and \n",
    "$$\\max \\Lambda'(x) = \\Lambda'(0) = \\max \\frac{e^0}{(1+e^0)^2} = \\frac{1}{4}$$\n",
    "Therefore, we have that:\n",
    "$$EM(x_1) \\approx \\frac{\\beta_1}{4}$$\n",
    "\n",
    "The \"rule-of-thumb\" thus divides all regression coefficients by 4 to approximate the marginal effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "marginal_effects[\"rule_of_thumb\"] = coeffs[\"logit\"][\"sm\"]/4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By modifying the dataset (\"passage de tout le monde en licence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "brute_force = pd.Series()\n",
    "for category in filters:\n",
    "    for pivot in params[category]:\n",
    "        non_pivots = [x for x in params[category] if x != pivot]\n",
    "        \n",
    "        X_one = X[\"t1\"].copy() \n",
    "        X_one[non_pivots] = 0\n",
    "        X_one[pivot] = 1\n",
    "\n",
    "#         proba_one = reg_logit_sk.predict_proba(X_one).T[1].mean()\n",
    "#         proba_t1 = reg_logit_sk.predict_proba(X[\"t1\"]).T[1].mean()\n",
    "        proba_one = reg_logit_sm.predict(sm.add_constant(X_one, has_constant=\"add\")).mean()\n",
    "        proba_t1 = reg_logit_sm.predict(sm.add_constant(X[\"t1\"])).mean()\n",
    "        brute_force[pivot] = proba_one - proba_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>etranger_</th>\n",
       "      <th>age15_</th>\n",
       "      <th>age30_</th>\n",
       "      <th>age40_</th>\n",
       "      <th>dip10_</th>\n",
       "      <th>dip11_</th>\n",
       "      <th>dip30_</th>\n",
       "      <th>dip31_</th>\n",
       "      <th>dip33_</th>\n",
       "      <th>dip41_</th>\n",
       "      <th>dip42_</th>\n",
       "      <th>dip50_</th>\n",
       "      <th>dip60_</th>\n",
       "      <th>dip70_</th>\n",
       "      <th>female_</th>\n",
       "      <th>enfants_</th>\n",
       "      <th>region1_</th>\n",
       "      <th>region2_</th>\n",
       "      <th>domtom_</th>\n",
       "      <th>const</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>analytical</th>\n",
       "      <td>0.1148</td>\n",
       "      <td>0.2652</td>\n",
       "      <td>0.0518</td>\n",
       "      <td>-0.0126</td>\n",
       "      <td>-0.3164</td>\n",
       "      <td>-0.3934</td>\n",
       "      <td>-0.1747</td>\n",
       "      <td>-0.3016</td>\n",
       "      <td>-0.3550</td>\n",
       "      <td>-0.0866</td>\n",
       "      <td>-0.2321</td>\n",
       "      <td>-0.1606</td>\n",
       "      <td>0.0249</td>\n",
       "      <td>-0.0304</td>\n",
       "      <td>0.0860</td>\n",
       "      <td>-0.0757</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>0.0434</td>\n",
       "      <td>0.1003</td>\n",
       "      <td>-0.1159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rule_of_thumb</th>\n",
       "      <td>0.1729</td>\n",
       "      <td>0.3993</td>\n",
       "      <td>0.0779</td>\n",
       "      <td>-0.0190</td>\n",
       "      <td>-0.4763</td>\n",
       "      <td>-0.5922</td>\n",
       "      <td>-0.2629</td>\n",
       "      <td>-0.4540</td>\n",
       "      <td>-0.5344</td>\n",
       "      <td>-0.1303</td>\n",
       "      <td>-0.3494</td>\n",
       "      <td>-0.2418</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>-0.0457</td>\n",
       "      <td>0.1294</td>\n",
       "      <td>-0.1139</td>\n",
       "      <td>0.0510</td>\n",
       "      <td>0.0653</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>-0.1744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               etranger_  age15_  age30_  age40_  dip10_  dip11_  dip30_  \\\n",
       "analytical    0.1148     0.2652  0.0518  -0.0126 -0.3164 -0.3934 -0.1747   \n",
       "rule_of_thumb 0.1729     0.3993  0.0779  -0.0190 -0.4763 -0.5922 -0.2629   \n",
       "\n",
       "               dip31_  dip33_  dip41_  dip42_  dip50_  dip60_  dip70_  \\\n",
       "analytical    -0.3016 -0.3550 -0.0866 -0.2321 -0.1606 0.0249  -0.0304   \n",
       "rule_of_thumb -0.4540 -0.5344 -0.1303 -0.3494 -0.2418 0.0374  -0.0457   \n",
       "\n",
       "               female_  enfants_  region1_  region2_  domtom_   const  \n",
       "analytical    0.0860   -0.0757   0.0339    0.0434    0.1003   -0.1159  \n",
       "rule_of_thumb 0.1294   -0.1139   0.0510    0.0653    0.1510   -0.1744  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# marginal_effects[\"brute_force\"] = brute_force\n",
    "marginal_effects.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratios = marginal_effects.copy()\n",
    "ratios = ratios.div(ratios[\"analytical\"], axis=0)\n",
    "ratios.transpose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
